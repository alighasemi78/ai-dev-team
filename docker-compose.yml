services:
  llm-engine:
    build: .
    runtime: nvidia # CRITICAL: This requires the NVIDIA Container Toolkit
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # Helpful for debugging CUDA errors
      - CUDA_LAUNCH_BLOCKING=1
    volumes:
      # Map the container's cache to a local folder so you download the model only once
      - ./hf_cache:/root/.cache/huggingface
      # Map the code so you can edit locally and run instantly
      - ./app:/app/app
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]